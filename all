######################################################################## Practical 4 - Classification Algorithm ##########################################################################

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

iris = load_iris()


X = iris.data
y = iris.target


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


logreg = LogisticRegression()
logreg.fit(X_train_scaled, y_train)


y_pred_train = logreg.predict(X_train_scaled)
y_pred_test = logreg.predict(X_test_scaled)



train_accuracy = accuracy_score(y_train, y_pred_train)
test_accuracy = accuracy_score(y_test, y_pred_test)



print("Training Accuracy : ", train_accuracy)
print("Testing Accuracy : ", test_accuracy)

print("Classification Report on Test Data : ")
print(classification_report(y_test, y_pred_test))


######################################################################### Practical 5 - Clustering Algorithm ################################################################################

from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

iris = load_iris()

X = iris.data

kmeans = KMeans(n_clusters=3)
kmeans.fit(X)

centroids = kmeans.cluster_centers_
labels = kmeans.labels_

plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, c='red')
plt.title('K-Means Clustering')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()



####################################################################################### Practical 6 ####################################################################################




############################################################################### Practical 8 - Student Grade #############################################################################

def map_function(student_scores):
    """
    Emits tuples of student_id and score.
    """
    for student_id, score in student_scores:
        yield student_id, score

def reduce_function(mapped_data):
    """
    Assigns grades based on scores.
    """
    grades = {}
    for student_id, score in mapped_data:
        if score > 80:
            grade = 'A'
        elif score > 60:
            grade = 'B'
        elif score > 40:
            grade = 'C'
        else:
            grade = 'D'
        grades[student_id] = grade
    return grades

def map_reduce(student_scores):
    """
    Simulates the MapReduce process for assigning grades to students based on scores.
    """
    mapped_data = list(map_function(student_scores))
    grades = reduce_function(mapped_data)
    return grades

student_scores = []

n = int(input("Enter the number of students: "))

for i in range(n): # replace i with _ in .py file
    while True:
        try:
            student_id = int(input("Enter student ID: "))
            break
        except ValueError:
            print("Invalid ID. Please enter an integer.")
    while True:
        try:
            score = float(input("Enter score for student {}: ".format(student_id)))
            break
        except ValueError:
            print("Invalid score. Please enter a number.")
    student_scores.append((student_id, score))

grades = map_reduce(student_scores)
for student_id, grade in grades.items():
    print(f"Student {student_id} has been assigned grade {grade}.")


############################################################################### Practical 9 - Gender based analysis #############################################################################

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_openml


def load_titanic_data():
    """
    Loads the Titanic dataset using Seaborn or Scikit-Learn.
    """
    try:
        df = sns.load_dataset("titanic")  # Load using Seaborn
    except:
        titanic = fetch_openml('titanic', version=1, as_frame=True)
        df = titanic.data
    return df


def map_reduce_with_pandas(df):
   """
    Simulates a MapReduce process using Pandas to analyze Titanic dataset.
    """
 # Map: Filter deceased males and transform data for average age calculation
   deceased_males = df[(df['survived'] == 0) & (df['sex'] == 'male')]
 # Reduce: Calculate average age of deceased males
   average_age_deceased_males = deceased_males['age'].mean()
 # Map: Filter deceased females and transform data for count by class
   deceased_females_by_class = df[(df['survived'] == 0) & (df['sex'] == 'female')]
 # Reduce: Count deceased females by class
   count_deceased_females_by_class = deceased_females_by_class['class'].value_counts()
 # Visualization 1: Age distribution of deceased males
   plt.figure(figsize=(8, 5))
   sns.histplot(deceased_males['age'].dropna(), bins=15, kde=True, color='blue')
   plt.title('Age Distribution of Deceased Males')
   plt.xlabel('Age')
   plt.ylabel('Frequency')
   plt.show()
 # Visualization 2: Count of deceased females by class
   plt.figure(figsize=(8, 5))
   sns.barplot(x=count_deceased_females_by_class.index, y=count_deceased_females_by_class.values, palette='coolwarm')
   plt.title('Count of Deceased Females by Class')
   plt.xlabel('Class')
   plt.ylabel('Count')
   plt.show()
   return average_age_deceased_males, count_deceased_females_by_class


 # Load dataset
df = load_titanic_data()
df

average_age, female_class_count = map_reduce_with_pandas(df)
print(f"Average age of males who died: {average_age:.2f}")
print("Number of deceased females in each class:")
print(female_class_count)
